# 将Janus获取到的音频合并混音成一个mp3

---

采用janus-pp-rec 转码为opus, 使用ffmpeg完成转码和混音

## 从保存的文件还原为opus音频数据

## 将opus文件转码为mp3
*  有个比较神奇的地方，opus转码为mp3体积变大了很多，
*  可能下一步的混音并不需要将opus提前转码成mp3，直接操作即可

```
ffmpeg -i record.opus record.mp3
```

## 将多段mp3混音成一个mp3文件
*  参考 [FFmpeg命令行语法之-filter_complex ](http://www.jianshu.com/p/b30f07055e2e)
*  参考 [how to merge multiple audio with time offset into a video](https://stackoverflow.com/questions/44231906/ffmpeg-how-to-merge-multiple-audio-with-time-offset-into-a-video)
*  参考 [Linux下ffmpeg安装实现音频拼接](http://blog.csdn.net/qq_21267705/article/details/73614731)
*  参考 [翻译ffmpeg-all文档-音频滤镜](http://blog.chinaunix.net/uid-10062010-id-5137260.html)

```
ffmpeg -i 0.mp3 -i 1_clip.mp3 -i 2_clip.mp3 -filter_complex "[1]adelay=10000|10000[s1];[2]adelay=20000|20000[s2];[0][s1][s2]amix=inputs=3:duration=longest:dropout_transition=2" out.mp3
# 将1_clip.mp3 2_clip.mp3 分别两声道分别延迟10s，20s 持续时间为最长持续时间进行混音
```
`filter_complex` 功能比较强大，可以找找官方文档学习学习。参数里面的[1]表示第二个输入，也就是1_clip.mp3，后面的[s1]是我给的别名，代表的是这一个操作

`adelay` 表示延迟一个或者多个音频通道，参数是以|分隔的列表字符串，分别用于指明对应各个通道延迟的毫秒（milliseconds）数。应提供至少一个大于0的延迟。未使用的延迟将被静默忽略。如果延迟值数量小于通道数量，则剩余通道不会被延迟。例：`adelay=1500|0|500`第一通道延迟1.5秒，第三通道0.5秒（其它通道均不延迟变化）。在我们上面最先给出的命令里面，[s1]的操作实际上就是将第二个输入的声道1和声道2都延迟10秒。

`amix` 混合多个音频输入到单路音频输出（叠加混合音频,与amerge不同)。注意这个滤镜只支持浮动采样，如果amix滤镜输入有一个整数采样，则aresample滤镜会自动插入转换成浮动采样。例： `ffmpeg -i INPUT1 -i INPUT2 -i INPUT3 -filter_complex amix=inputs=3:duration=first:dropout_transition=3 OUTPUT`
把3个输入音频流混合成一个输出流，持续时间采用第一个输入流的持续时间并且有3秒的结束过渡。
它支持下面的参数：
```
inputs 
    输入数，如果没有指定则默认为2

duration
    确定流结束的方法，有三种：
    longest : 按最长持续时间输入（默认） 
    shortest: 按最短持续时间输入 
    first   : 按第一个输入持续时间

dropout_transition
    过渡时间，单位秒，指一个输入流结束时音量从正常到无声渐止效果，默认为2秒
```